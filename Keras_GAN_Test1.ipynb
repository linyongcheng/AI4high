{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_GAN_Test1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyDearGreatTeacher/AI4high/blob/master/Keras_GAN_Test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8vsBuFBjMQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2300
        },
        "outputId": "0dad2e46-5970-4f2d-d520-7be1635db1cf"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pylab as plt\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, ReLU, LeakyReLU, Dense\n",
        "from keras.layers.core import Activation, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.datasets import cifar10\n",
        "from keras import initializers\n",
        "\n",
        "\n",
        "def build_cifar10_discriminator(ndf=64, image_shape=(32, 32, 3)):\n",
        "    \"\"\" Builds CIFAR10 DCGAN Discriminator Model\n",
        "    PARAMS\n",
        "    ------\n",
        "    ndf: number of discriminator filters\n",
        "    image_shape: 32x32x3\n",
        "    RETURN\n",
        "    ------\n",
        "    D: keras sequential\n",
        "    \"\"\"\n",
        "    init = initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "    D = Sequential()\n",
        "\n",
        "    # Conv 1: 16x16x64\n",
        "    D.add(Conv2D(ndf, kernel_size=5, strides=2, padding='same',\n",
        "                 use_bias=True, kernel_initializer=init,\n",
        "                 input_shape=image_shape))\n",
        "    D.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 2: 8x8x128\n",
        "    D.add(Conv2D(ndf*2, kernel_size=5, strides=2, padding='same',\n",
        "          use_bias=True, kernel_initializer=init))\n",
        "    D.add(BatchNormalization())\n",
        "    D.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 3: 4x4x256\n",
        "    D.add(Conv2D(ndf*4, kernel_size=5, strides=2, padding='same',\n",
        "                 use_bias=True, kernel_initializer=init))\n",
        "    D.add(BatchNormalization())\n",
        "    D.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 4:  2x2x512\n",
        "    D.add(Conv2D(ndf*8, kernel_size=5, strides=2, padding='same',\n",
        "                 use_bias=True, kernel_initializer=init))\n",
        "    D.add(BatchNormalization())\n",
        "    D.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Flatten: 2x2x512 -> (2048)\n",
        "    D.add(Flatten())\n",
        "\n",
        "    # Dense Layer\n",
        "    D.add(Dense(1, kernel_initializer=init))\n",
        "    D.add(Activation('sigmoid'))\n",
        "\n",
        "    print(\"\\nDiscriminator\")\n",
        "    D.summary()\n",
        "\n",
        "    return D\n",
        "\n",
        "\n",
        "def build_cifar10_generator(ngf=64, z_dim=128):\n",
        "    \"\"\" Builds CIFAR10 DCGAN Generator Model\n",
        "    PARAMS\n",
        "    ------\n",
        "    ngf: number of generator filters\n",
        "    z_dim: number of dimensions in latent vector\n",
        "    RETURN\n",
        "    ------\n",
        "    G: keras sequential\n",
        "    \"\"\"\n",
        "    init = initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "    G = Sequential()\n",
        "\n",
        "    # Dense 1: 2x2x512\n",
        "    G.add(Dense(2*2*ngf*8, input_shape=(z_dim, ),\n",
        "        use_bias=True, kernel_initializer=init))\n",
        "    G.add(Reshape((2, 2, ngf*8)))\n",
        "    G.add(BatchNormalization())\n",
        "    G.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 1: 4x4x256\n",
        "    G.add(Conv2DTranspose(ngf*4, kernel_size=5, strides=2, padding='same',\n",
        "          use_bias=True, kernel_initializer=init))\n",
        "    G.add(BatchNormalization())\n",
        "    G.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 2: 8x8x128\n",
        "    G.add(Conv2DTranspose(ngf*2, kernel_size=5, strides=2, padding='same',\n",
        "          use_bias=True, kernel_initializer=init))\n",
        "    G.add(BatchNormalization())\n",
        "    G.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 3: 16x16x64\n",
        "    G.add(Conv2DTranspose(ngf, kernel_size=5, strides=2, padding='same',\n",
        "          use_bias=True, kernel_initializer=init))\n",
        "    G.add(BatchNormalization())\n",
        "    G.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv 4: 32x32x3\n",
        "    G.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same',\n",
        "          use_bias=True, kernel_initializer=init))\n",
        "    G.add(Activation('tanh'))\n",
        "\n",
        "    print(\"\\nGenerator\")\n",
        "    G.summary()\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    # load cifar10 data\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    # convert train and test data to float32\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # scale train and test data to [-1, 1]\n",
        "    X_train = (X_train / 255) * 2 - 1\n",
        "    X_test = (X_train / 255) * 2 - 1\n",
        "\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def plot_images(images, filename):\n",
        "    h, w, c = images.shape[1:]\n",
        "    grid_size = ceil(np.sqrt(images.shape[0]))\n",
        "    images = (images.reshape(grid_size, grid_size, h, w, c)\n",
        "              .transpose(0, 2, 1, 3, 4)\n",
        "              .reshape(grid_size*h, grid_size*w, c))\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    plt.imsave(filename, images)\n",
        "\n",
        "\n",
        "def plot_losses(losses_d, losses_g, filename):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 2))\n",
        "    axes[0].plot(losses_d)\n",
        "    axes[1].plot(losses_g)\n",
        "    axes[0].set_title(\"losses_d\")\n",
        "    axes[1].set_title(\"losses_g\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(ndf=64, ngf=64, z_dim=100, lr_d=2e-4, lr_g=2e-4, epochs=100,\n",
        "          batch_size=128, epoch_per_checkpoint=1, n_checkpoint_images=36):\n",
        "\n",
        "    X_train, _ = get_data()\n",
        "    image_shape = X_train[0].shape\n",
        "    print(\"image shape {}, min val {}, max val {}\".format(\n",
        "        image_shape, X_train[0].min(), X_train[0].max()))\n",
        "\n",
        "    # plot real images for reference\n",
        "    plot_images(X_train[:n_checkpoint_images], \"real_images.png\")\n",
        "\n",
        "    # build models\n",
        "    D = build_cifar10_discriminator(ndf, image_shape)\n",
        "    G = build_cifar10_generator(ngf, z_dim)\n",
        "\n",
        "    # define Discriminator's optimizer\n",
        "    D.compile(Adam(lr=lr_d, beta_1=0.5), loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "    # define D(G(z)) graph for training the Generator\n",
        "    D.trainable = False\n",
        "    z = Input(shape=(z_dim, ))\n",
        "    D_of_G = Model(inputs=z, outputs=D(G(z)))\n",
        "\n",
        "    # define Generator's Optimizer\n",
        "    D_of_G.compile(Adam(lr=lr_g, beta_1=0.5), loss='binary_crossentropy',\n",
        "                   metrics=['binary_accuracy'])\n",
        "\n",
        "    # get labels for computing the losses\n",
        "    labels_real = np.ones(shape=(batch_size, 1))\n",
        "    labels_fake = np.zeros(shape=(batch_size, 1))\n",
        "\n",
        "    losses_d, losses_g = [], []\n",
        "\n",
        "    # fix a z vector for training evaluation\n",
        "    z_fixed = np.random.uniform(-1, 1, size=(n_checkpoint_images, z_dim))\n",
        "\n",
        "    # training loop\n",
        "    for e in range(epochs):\n",
        "        print(\"Epoch {}\".format(e))\n",
        "        for i in range(len(X_train) // batch_size):\n",
        "\n",
        "            # update Discriminator weights\n",
        "            D.trainable = True\n",
        "\n",
        "            # Get real samples\n",
        "            real_images = X_train[i*batch_size:(i+1)*batch_size]\n",
        "            loss_d_real = D.train_on_batch(x=real_images, y=labels_real)[0]\n",
        "\n",
        "            # Fake Samples\n",
        "            z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
        "            fake_images = G.predict_on_batch(z)\n",
        "            loss_d_fake = D.train_on_batch(x=fake_images, y=labels_fake)[0]\n",
        "\n",
        "            # Compute Discriminator's loss\n",
        "            loss_d = 0.5 * (loss_d_real + loss_d_fake)\n",
        "\n",
        "            # update Generator weights, do not update Discriminator weights\n",
        "            D.trainable = False\n",
        "            loss_g = D_of_G.train_on_batch(x=z, y=labels_real)[0]\n",
        "\n",
        "        losses_d.append(loss_d)\n",
        "        losses_g.append(loss_g)\n",
        "\n",
        "        if (e % epoch_per_checkpoint) == 0:\n",
        "            print(\"loss_d={:.5f}, loss_g={:.5f}\".format(loss_d, loss_g))\n",
        "            fake_images = G.predict(z_fixed)\n",
        "            print(\"\\tPlotting images and losses\")\n",
        "            plot_images(fake_images, \"fake_images_e{}.png\".format(e))\n",
        "            plot_losses(losses_d, losses_g, \"losses.png\")\n",
        "\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image shape (32, 32, 3), min val -1.0, max val 1.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "Discriminator\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 2049      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,312,193\n",
            "Trainable params: 4,310,401\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "\n",
            "Generator\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 256)         3277056   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 128)         819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 3)         4803      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 4,516,739\n",
            "Trainable params: 4,514,819\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "loss_d=0.33136, loss_g=3.13065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 1\n",
            "loss_d=0.23253, loss_g=3.71206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 2\n",
            "loss_d=1.71165, loss_g=10.26139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 3\n",
            "loss_d=0.03609, loss_g=3.07774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 4\n",
            "loss_d=0.40931, loss_g=4.54641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 5\n",
            "loss_d=0.29662, loss_g=0.41505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 6\n",
            "loss_d=1.97529, loss_g=3.60765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 7\n",
            "loss_d=0.04259, loss_g=7.28084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 8\n",
            "loss_d=0.09553, loss_g=0.22540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 9\n",
            "loss_d=0.07846, loss_g=4.52091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 10\n",
            "loss_d=0.42822, loss_g=4.54761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tPlotting images and losses\n",
            "Epoch 11\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}