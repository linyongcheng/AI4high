{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_2_MLP_TBTested.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyDearGreatTeacher/AI4high/blob/master/TF_2_MLP_TBTested.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLcpqav_RgNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "# name of data file\n",
        "birth_weight_file = 'birth_weight.csv'\n",
        "birthdata_url = 'https://github.com/nfmcclure/tensorflow_cookbook/raw/master' \\\n",
        "                '/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n",
        "\n",
        "# Download data and create data file if file does not exist in current directory\n",
        "if not os.path.exists(birth_weight_file):\n",
        "    birth_file = requests.get(birthdata_url)\n",
        "    birth_data = birth_file.text.split('\\r\\n')\n",
        "    birth_header = birth_data[0].split('\\t')\n",
        "    birth_data = [[float(x) for x in y.split('\\t') if len(x) >= 1]\n",
        "                  for y in birth_data[1:] if len(y) >= 1]\n",
        "    with open(birth_weight_file, \"w\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows([birth_header])\n",
        "        writer.writerows(birth_data)\n",
        "\n",
        "# read birth weight data into memory\n",
        "birth_data = []\n",
        "with open(birth_weight_file, newline='') as csvfile:\n",
        "    csv_reader = csv.reader(csvfile)\n",
        "    birth_header = next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        birth_data.append(row)\n",
        "\n",
        "birth_data = [[float(x) for x in row] for row in birth_data]\n",
        "\n",
        "# Extract y-target (birth weight)\n",
        "y_vals = np.array([x[8] for x in birth_data])\n",
        "\n",
        "# Filter for features of interest\n",
        "cols_of_interest = ['AGE', 'LWT', 'RACE', 'SMOKE', 'PTL', 'HT', 'UI']\n",
        "x_vals = np.array([[x[ix] for ix, feature in enumerate(birth_header) if feature in cols_of_interest]\n",
        "                   for x in birth_data])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5PCJINjRlRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "birth_data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs9Q2hcHRM9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "85ee14bf-4285-4109-80b1-cb26c308feb6"
      },
      "source": [
        "\"\"\"\n",
        "Using a Multiple Layer Network\n",
        "------------------------------\n",
        "illustrate how to use a Multiple Layer Network in TensorFlow\n",
        "\n",
        "Low Birthrate data:\n",
        "Columns    Variable                                Abbreviation\n",
        "----------------------------------------------------------------\n",
        "Low Birth Weight (0 = Birth Weight >= 2500g,            LOW\n",
        "                  1 = Birth Weight < 2500g)\n",
        "Age of the Mother in Years                              AGE\n",
        "Weight in Pounds at the Last Menstrual Period           LWT\n",
        "Race (1 = White, 2 = Black, 3 = Other)                  RACE\n",
        "Smoking Status During Pregnancy (1 = Yes, 0 = No)       SMOKE\n",
        "History of Premature Labor (0 = None  1 = One, etc.)    PTL\n",
        "History of Hypertension (1 = Yes, 0 = No)               HT\n",
        "Presence of Uterine Irritability (1 = Yes, 0 = No)      UI\n",
        "Birth Weight in Grams                                   BWT\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "The multiple neural network layer we will create will be composed of\n",
        "three fully connected hidden layers, with node sizes 50, 25, and 5\n",
        "\"\"\"\n",
        "\n",
        "# Reset the graph for new run\n",
        "ops.reset_default_graph()\n",
        "\n",
        "# Create graph session \n",
        "sess = tf.Session()\n",
        "\n",
        "# set batch size for training\n",
        "batch_size = 100\n",
        "\n",
        "# Set random seed to make results reproducible\n",
        "seed = 4\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "# Split data into train/test = 80%/20%\n",
        "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
        "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
        "x_vals_train = x_vals[train_indices]\n",
        "x_vals_test = x_vals[test_indices]\n",
        "y_vals_train = y_vals[train_indices]\n",
        "y_vals_test = y_vals[test_indices]\n",
        "\n",
        "# Normalize by column (min-max norm to be between 0 and 1)\n",
        "def normalize_cols(m, col_min=np.array([None]), col_max=np.array([None])):\n",
        "    if not col_min[0]:\n",
        "        col_min = m.min(axis=0)\n",
        "    if not col_max[0]:\n",
        "        col_max = m.max(axis=0)\n",
        "    return (m - col_min) / (col_max - col_min), col_min, col_max\n",
        "\n",
        "\n",
        "x_vals_train, train_min, train_max = np.nan_to_num(normalize_cols(x_vals_train))\n",
        "x_vals_test, _, _ = np.nan_to_num(normalize_cols(x_vals_test, train_min, train_max))\n",
        "\n",
        "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train, train_max, train_min))\n",
        "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test, train_max, train_min))\n",
        "\n",
        "\n",
        "# Define Variable Functions (weights and bias)\n",
        "def init_weight(shape, st_dev):\n",
        "    weight = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
        "    return weight\n",
        "\n",
        "\n",
        "def init_bias(shape, st_dev):\n",
        "    bias = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
        "    return bias\n",
        "\n",
        "# Create Placeholders\n",
        "x_data = tf.placeholder(shape=[None, 7], dtype=tf.float32)\n",
        "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
        "\n",
        "\n",
        "# Create a fully connected layer:\n",
        "def fully_connected(input_layer, weights, biases):\n",
        "    layer = tf.add(tf.matmul(input_layer, weights), biases)\n",
        "    return tf.nn.relu(layer)\n",
        "\n",
        "# -------Create the first layer (50 hidden nodes)--------\n",
        "weight_1 = init_weight(shape=[7, 25], st_dev=10.0)\n",
        "bias_1 = init_bias(shape=[25], st_dev=10.0)\n",
        "layer_1 = fully_connected(x_data, weight_1, bias_1)\n",
        "\n",
        "# -------Create second layer (25 hidden nodes)--------\n",
        "weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n",
        "bias_2 = init_bias(shape=[10], st_dev=10.0)\n",
        "layer_2 = fully_connected(layer_1, weight_2, bias_2)\n",
        "\n",
        "\n",
        "# -------Create third layer (5 hidden nodes)--------\n",
        "weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n",
        "bias_3 = init_bias(shape=[3], st_dev=10.0)\n",
        "layer_3 = fully_connected(layer_2, weight_3, bias_3)\n",
        "\n",
        "\n",
        "# -------Create output layer (1 output value)--------\n",
        "weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n",
        "bias_4 = init_bias(shape=[1], st_dev=10.0)\n",
        "final_output = fully_connected(layer_3, weight_4, bias_4)\n",
        "\n",
        "# Declare loss function (L1)\n",
        "loss = tf.reduce_mean(tf.abs(y_target - final_output))\n",
        "\n",
        "# Declare optimizer\n",
        "my_opt = tf.train.AdamOptimizer(0.05)\n",
        "train_step = my_opt.minimize(loss)\n",
        "\n",
        "# Initialize Variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# Training loop\n",
        "loss_vec = []\n",
        "test_loss = []\n",
        "for i in range(200):\n",
        "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
        "    rand_x = x_vals_train[rand_index]\n",
        "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
        "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
        "\n",
        "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
        "    loss_vec.append(temp_loss)\n",
        "    \n",
        "    test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
        "    test_loss.append(test_temp_loss)\n",
        "    if (i+1) % 25 == 0:\n",
        "        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))\n",
        "\n",
        "# Plot loss (MSE) over time\n",
        "plt.plot(loss_vec, 'k-', label='Train Loss')\n",
        "plt.plot(test_loss, 'r--', label='Test Loss')\n",
        "plt.title('Loss (MSE) per Generation')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# Model Accuracy\n",
        "actuals = np.array([x[0] for x in birth_data])\n",
        "test_actuals = actuals[test_indices]\n",
        "train_actuals = actuals[train_indices]\n",
        "test_preds = [x[0] for x in sess.run(final_output, feed_dict={x_data: x_vals_test})]\n",
        "train_preds = [x[0] for x in sess.run(final_output, feed_dict={x_data: x_vals_train})]\n",
        "test_preds = np.array([0.0 if x < 2500.0 else 1.0 for x in test_preds])\n",
        "train_preds = np.array([0.0 if x < 2500.0 else 1.0 for x in train_preds])\n",
        "# Print out accuracies\n",
        "test_acc = np.mean([x == y for x, y in zip(test_preds, test_actuals)])\n",
        "train_acc = np.mean([x == y for x, y in zip(train_preds, train_actuals)])\n",
        "print('On predicting the category of low birthweight from regression output (<2500g):')\n",
        "print('Test Accuracy: {}'.format(test_acc))\n",
        "print('Train Accuracy: {}'.format(train_acc))\n",
        "\n",
        "# Evaluate new points on the model\n",
        "# Need vectors of 'AGE', 'LWT', 'RACE', 'SMOKE', 'PTL', 'HT', 'UI'\n",
        "new_data = np.array([[35, 185, 1., 0., 0., 0., 1.],\n",
        "                     [18, 160, 0., 1., 0., 0., 1.]])\n",
        "new_data_scaled = np.nan_to_num(normalize_cols(new_data, train_max, train_min))\n",
        "new_logits = [x[0] for x in sess.run(final_output, feed_dict={x_data: new_data_scaled})]\n",
        "new_preds = np.array([1.0 if x < 2500.0 else 0.0 for x in new_logits])\n",
        "\n",
        "print('New Data Predictions: {}'.format(new_preds))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c2d483c5fa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mrand_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_vals_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mrand_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_vals_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrand_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrand_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtemp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrand_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrand_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    }
  ]
}